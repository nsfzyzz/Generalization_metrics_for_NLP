{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use this file to generate the slurm array configurations \n",
    "## Also, note that the code will generate the checkpoint folders in the folder that you specify below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remember to change the checkpoint directory\n",
    "ckpt_root = '/data/user-name/Generalization_metrics_for_NLP/checkpoint/'\n",
    "\n",
    "# Select the \"sample x learning rate x depth\" grid or the \"sample x learning rate x width\" grid\n",
    "grid = 'depth'  # choices = ['depth', 'width']\n",
    "\n",
    "# Select training or evaluating generalization metrics\n",
    "experiment = 'train'  # choices = ['train', 'eval_metrics']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "assert os.path.exists(ckpt_root)\n",
    "assert grid in ['depth', 'width']\n",
    "assert experiment in ['train', 'eval_metrics']\n",
    "\n",
    "lrs = [0.0625, 0.125, 0.25, 0.375, 0.5, 0.625, 0.75, 1.0]\n",
    "widths = [256, 384, 512, 768, 1024]\n",
    "width_standard = 512\n",
    "head_standard = 8\n",
    "heads = [4, 6, 8, 12, 16]\n",
    "samples = [160000, 320000, 640000, 1280000, 2560000]\n",
    "depths = [4, 5, 6, 7, 8]\n",
    "depth_standard = 6\n",
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the following code to generate the config files for training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_configure_file(configs, sample, depth, width, lr, dropout, head):\n",
    "    \n",
    "    hyperparameter_string = f'WMT14_sample{sample}_depth{depth}_width{width}_lr{lr}_dropout{dropout}'\n",
    "    ckpt_folder = os.path.join(ckpt_root, hyperparameter_string)\n",
    "    if not os.path.exists(ckpt_folder):\n",
    "        os.makedirs(ckpt_folder)\n",
    "    \n",
    "    for task, suffix in zip(tasks, suffixes):\n",
    "        task_completion_file = os.path.join(ckpt_folder, suffix)\n",
    "\n",
    "        if task == 'train':\n",
    "            ## Check if the final training result exists.\n",
    "            ## If not, put the task in the training list.\n",
    "            if os.path.exists(task_completion_file):\n",
    "                print(f\"Task {task} finished for sample={sample}, lr={lr}, depth={depth}, width={width}.\")\n",
    "            else:\n",
    "                configs[task].append(f\"{sample} {depth} {width} {lr} {dropout} {head}\")\n",
    "        else:\n",
    "            ## Check if the final training result exists and if the evaluation result does not exist.\n",
    "            ## If so, put the task in the evaluation list.\n",
    "            training_completion_file = os.path.join(ckpt_folder, 'net_epoch_20.ckpt')\n",
    "            if os.path.exists(training_completion_file) and not os.path.exists(task_completion_file):\n",
    "                configs[task].append(f\"{sample} {depth} {width} {lr} {dropout} {head}\")\n",
    "\n",
    "                \n",
    "if experiment=='train':\n",
    "    tasks = ['train']\n",
    "    suffixes = ['net_epoch_20.ckpt']\n",
    "else:\n",
    "    tasks = ['bleu', 'ww_tpl', 'ww_pl', 'ww_exponential', 'robust']\n",
    "    suffixes = ['bleu_loss.jsonl', 'results.pkl', 'results_original_alpha.pkl', 'results_exponential.pkl', 'robust_measures.pkl']\n",
    "\n",
    "configs = {x:[] for x in tasks}\n",
    "\n",
    "## The following code only puts unfinished tasks to the configure file\n",
    "\n",
    "for sample in samples:\n",
    "    for lr in lrs:\n",
    "        if grid == 'depth':\n",
    "            for depth in depths:\n",
    "                width = width_standard\n",
    "                head = head_standard\n",
    "                change_configure_file(configs, sample, depth, width, lr, dropout, head)\n",
    "        else:\n",
    "            for width, head in zip(widths, heads):\n",
    "                depth = depth_standard\n",
    "                change_configure_file(configs, sample, depth, width, lr, dropout, head)\n",
    "                    \n",
    "## write the unfinished tasks into the final configuration file\n",
    "for task in tasks:\n",
    "    with open(f'{task}_config.txt', 'w') as f:\n",
    "        for line in configs[task]:\n",
    "            f.write(line+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NLP_metrics",
   "language": "python",
   "name": "nlp_metrics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
